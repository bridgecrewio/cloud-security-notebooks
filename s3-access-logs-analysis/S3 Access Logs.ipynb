{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# S3 Access Logs report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --upgrade pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters and AWS session configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import os\n",
    "import io\n",
    "import time\n",
    "import pandas as pd\n",
    "\n",
    "pd.options.display.width = 0\n",
    "\n",
    "%env S3_ACCESS_LOGS_BUCKET=<YOUR_S3_ACCESS_LOGS_BUCKET>\n",
    "%env OUTPUT_BUCKET_NAME=<YOUR_OUTPUT_BUCKET>\n",
    "%env ATHENA_DATABASE_NAME=s3_access_logs\n",
    "%env ATHENA_TABLE_NAME=s3_access_logs_table\n",
    "%env ATHENA_VIEW_NAME=s3_access_logs_view\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Access Logs analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Athena configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_input = 's3://{}/'.format(os.environ['S3_ACCESS_LOGS_BUCKET'])\n",
    "s3_output_bucket_name = process.env['OUTPUT_BUCKET_NAME']\n",
    "s3_output_path = 's3://{}'.format(s3_output_bucket_name)\n",
    "database = process.env['ATHENA_DATABASE_NAME']\n",
    "table = process.env['ATHENA_TABLE_NAME']\n",
    "view_name = process.env['ATHENA_VIEW_NAME']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = boto3.client('athena')\n",
    "\n",
    "# Helper function for executing athena queries\n",
    "def run_query(query, s3_output, database=None):\n",
    "    if database is None:\n",
    "        response = client.start_query_execution(QueryString=query, ResultConfiguration={'OutputLocation': s3_output})\n",
    "    else:\n",
    "        response = client.start_query_execution(\n",
    "            QueryString=query,\n",
    "            QueryExecutionContext={'Database': database},\n",
    "            ResultConfiguration={'OutputLocation': s3_output}\n",
    "        )\n",
    "    return response\n",
    "\n",
    "def obtain_data(filename):\n",
    "    try:\n",
    "        objectKey = filename + '.csv'\n",
    "        resource = boto3.resource('s3')\n",
    "        response = resource.Bucket(s3_output_bucket_name).Object(key= objectKey).get()\n",
    "        return pd.read_csv(io.BytesIO(response['Body'].read()), encoding='utf8')   \n",
    "    except Exception as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Athena database, table, and view"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SQL commands to create Athena S3 Access Logs database, table definition and view\n",
    "create_database = \"CREATE DATABASE IF NOT EXISTS %s;\" % (database)\n",
    "\n",
    "create_table = \\\n",
    "    \"\"\"\n",
    "CREATE EXTERNAL TABLE `%s`(\n",
    "  `bucketowner` string COMMENT '',\n",
    "  `bucket` string COMMENT '',\n",
    "  `requestdatetime` string COMMENT '',\n",
    "  `remoteip` string COMMENT '',\n",
    "  `requester` string COMMENT '',\n",
    "  `requestid` string COMMENT '',\n",
    "  `operation` string COMMENT '',\n",
    "  `key` string COMMENT '',\n",
    "  `requesturi_operation` string COMMENT '',\n",
    "  `requesturi_key` string COMMENT '',\n",
    "  `requesturi_httpprotoversion` string COMMENT '',\n",
    "  `httpstatus` string COMMENT '',\n",
    "  `errorcode` string COMMENT '',\n",
    "  `bytessent` bigint COMMENT '',\n",
    "  `objectsize` bigint COMMENT '',\n",
    "  `totaltime` string COMMENT '',\n",
    "  `turnaroundtime` string COMMENT '',\n",
    "  `referrer` string COMMENT '',\n",
    "  `useragent` string COMMENT '',\n",
    "  `versionid` string COMMENT '',\n",
    "  `hostid` string COMMENT '',\n",
    "  `sigv` string COMMENT '',\n",
    "  `ciphersuite` string COMMENT '',\n",
    "  `authtype` string COMMENT '',\n",
    "  `endpoint` string COMMENT '',\n",
    "  `tlsversion` string COMMENT '')\n",
    "ROW FORMAT SERDE\n",
    "  'org.apache.hadoop.hive.serde2.RegexSerDe'\n",
    "WITH SERDEPROPERTIES (\n",
    "  'input.regex'='([^ ]*) ([^ ]*) \\\\\\[(.*?)\\\\\\] ([^ ]*) ([^ ]*) ([^ ]*) ([^ ]*) ([^ ]*) \\\\\\\\\\\\\\\"([^ ]*) ([^ ]*) (- |[^ ]*)\\\\\\\\\\\\\\\" (-|[0-9]*) ([^ ]*) ([^ ]*) ([^ ]*) ([^ ]*) ([^ ]*) ([^ ]*) (\\\\\\\"[^\\\\\\\"]*\\\\\\\") ([^ ]*)(?: ([^ ]*) ([^ ]*) ([^ ]*) ([^ ]*) ([^ ]*) ([^ ]*))?.*$')\n",
    "STORED AS INPUTFORMAT\n",
    "  'org.apache.hadoop.mapred.TextInputFormat'\n",
    "OUTPUTFORMAT\n",
    "  'org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat'\n",
    "LOCATION\n",
    "  '%s'\n",
    "TBLPROPERTIES (\n",
    "  'transient_lastDdlTime'='1573646113')\n",
    "    \"\"\" % ( table, s3_input )\n",
    "\n",
    "create_view = \\\n",
    " \"\"\"\n",
    " CREATE OR REPLACE VIEW %s AS \n",
    " SELECT DISTINCT bucket, tlsversion, requester\n",
    " FROM %s\"\"\" % (view_name, table)\n",
    "\n",
    "# creating the database if not exists\n",
    "create_db_result = run_query(create_database, s3_output_path)\n",
    "\n",
    "# Create the flowlogs table combining all collected data from the bucket\n",
    "create_s3_access_logs_table = run_query(create_table, s3_output_path, database)\n",
    "\n",
    "time.sleep(2) # So the view will be created after the table is created\n",
    "\n",
    "#Create \n",
    "create_s3_view = run_query(create_view, s3_output_path, database)\n",
    "# print(create_port_address_view)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Query the view with AWS Athena and obtain the results from S3 bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = run_query(\"SELECT DISTINCT * FROM {}.{} WHERE tlsversion NOT IN ('TLSv1.0', 'TLSv1.1', 'TLSv1.2', 'TLSv1.3')\".format(database, view_name), s3_output_path, database)\n",
    "execution_id = response['QueryExecutionId']\n",
    "athena = boto3.client('athena')\n",
    "\n",
    "status = \"RUNNING\"\n",
    "status = athena.get_query_execution(QueryExecutionId=execution_id)['QueryExecution']['Status']['State']\n",
    "while status == \"RUNNING\":\n",
    "    print('Query still running')\n",
    "    time.sleep(3)\n",
    "    status = athena.get_query_execution(QueryExecutionId=execution_id)['QueryExecution']['Status']['State']\n",
    "print('Query is DONE!');\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results\n",
    "The following buckets, if any, have had unsecure connections. For each such case, you may find the requester which made the unsecure call."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = obtain_data(execution_id)\n",
    "if len(results) == 0:\n",
    "    print('No unsecure connections detected')\n",
    "else:\n",
    "    print(results)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
